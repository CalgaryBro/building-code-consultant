# LLM Service Dependencies - llama.cpp version
fastapi==0.109.0
uvicorn[standard]==0.27.0
pydantic==2.5.3
pydantic-settings==2.1.0

# llama.cpp Python bindings - installed separately in Dockerfile
# using pre-built wheel to avoid compilation issues

# Resource Monitoring
psutil>=5.9.0
prometheus-client>=0.19.0

# HTTP client for model download
httpx>=0.25.0
